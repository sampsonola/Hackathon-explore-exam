{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd69ef0f",
   "metadata": {},
   "source": [
    "### Importing of Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d764c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-06-27 06:40:14 +01:00)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install ipython-autotime\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c92401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\samson\\appdata\\roaming\\python\\python39\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\samson\\anaconda3\\lib\\site-packages (from imblearn) (0.9.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\samson\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\samson\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\samson\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\users\\samson\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\samson\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "time: 5.62 s (started: 2022-06-27 06:40:14 +01:00)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "136e39a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SAMSON\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SAMSON\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.7 s (started: 2022-06-27 06:40:20 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "# Standard libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing\n",
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download(['stopwords','punkt'])\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.utils import resample\n",
    "from imblearn.pipeline import Pipeline\n",
    "# Building classification models\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef3bab1",
   "metadata": {},
   "source": [
    "### Loading of Dataset and general overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4933e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 219 ms (started: 2022-06-27 06:40:42 +01:00)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_set.csv')\n",
    "test = pd.read_csv('test_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc761c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 62 ms (started: 2022-06-27 06:40:42 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the labels and features\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b98f6418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "=============\n",
      "\n",
      "Shape of the dataset: (33000, 2)\n",
      "\n",
      "Total Number of unique tweets: 29948\n",
      "\n",
      "Total Number of missing values:\n",
      "lang_id    0\n",
      "text       0\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "TEST DATA\n",
      "=========\n",
      "\n",
      "Shape of the dataset: (5682, 2)\n",
      "\n",
      "Total Number of unique tweets: 5459\n",
      "\n",
      "Total Number of missing values:\n",
      "index    0\n",
      "text     0\n",
      "dtype: int64\n",
      "\n",
      "time: 250 ms (started: 2022-06-27 06:40:43 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#Taking general overview at both datasets\n",
    "print('TRAINING DATA')\n",
    "print('============='+('\\n'))\n",
    "print('Shape of the dataset: {}\\n'.format(train.shape))\n",
    "print('Total Number of unique tweets: {}\\n'.format(len(set(train['text']))))\n",
    "print('Total Number of missing values:\\n{}\\n\\n'.format(train.isnull().sum()))\n",
    "print('TEST DATA')\n",
    "print('========='+('\\n'))\n",
    "print('Shape of the dataset: {}\\n'.format(test.shape))\n",
    "print('Total Number of unique tweets: {}\\n'.format(len(set(test['text']))))\n",
    "print('Total Number of missing values:\\n{}\\n' .format(test.isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13f885e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ffeb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 187 ms (started: 2022-06-27 06:40:43 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def text_preprocessing(text):\n",
    "    \n",
    "    '''\n",
    "    This functions cleans text from line breaks, URLs, numbers, etc.\n",
    "    '''\n",
    "    \n",
    "    text = text.lower() #to lower case\n",
    "    text = text.replace('\\n', ' ') # remove line breaks\n",
    "    text = text.replace('\\@(\\w*)', '') # remove mentions\n",
    "    text = re.sub(r\"\\bhttps://t.co/\\w+\", '', text) # remove URLs\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # remove numbers\n",
    "    text = re.sub(r'\\#', '', text) # remove hashtags. To remove full hashtag: '\\#(\\w*)'\n",
    "    text = re.sub('\\w*\\d\\w*', '', text) # removes numbers?\n",
    "    text = re.sub(' +', ' ', text) # remove 1+ spaces\n",
    "    text = re.sub(\"\\n\",\" \",text)\n",
    "    text =' '.join(text.split())\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c7c4993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...\n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...\n",
       "2     eng  the province of kwazulu-natal department of tr...\n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...\n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 141 ms (started: 2022-06-27 06:40:43 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the labels and features\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db40632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Mmasepala, fa maemo a a kgethegileng a letlele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Uzakwaziswa ngokufaneleko nakungafuneka eminye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tshivhumbeo tshi fana na ngano dza vhathu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Kube inja nelikati betingevakala kutsi titsini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Winste op buitelandse valuta.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               text\n",
       "0      1  Mmasepala, fa maemo a a kgethegileng a letlele...\n",
       "1      2  Uzakwaziswa ngokufaneleko nakungafuneka eminye...\n",
       "2      3         Tshivhumbeo tshi fana na ngano dza vhathu.\n",
       "3      4  Kube inja nelikati betingevakala kutsi titsini...\n",
       "4      5                      Winste op buitelandse valuta."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2022-06-27 06:40:43 +01:00)\n"
     ]
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99898625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    29948\n",
       "True      3052\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 156 ms (started: 2022-06-27 06:40:43 +01:00)\n"
     ]
    }
   ],
   "source": [
    "train.text.duplicated(keep=\"first\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "977e967f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    5459\n",
       "True      223\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 140 ms (started: 2022-06-27 06:40:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "test.text.duplicated(keep=\"first\").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c51aa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated text in train data:\n",
      "0.0 %\n",
      "time: 47 ms (started: 2022-06-27 07:04:31 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Looking for duplicates\n",
    "percent_duplicates = round((1-(train['text'].nunique()/len(train['text'])))*100,2)\n",
    "print('Duplicated text in train data:')\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a5f3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29948, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 ms (started: 2022-06-27 06:40:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "train.drop_duplicates(subset=\"text\",keep=\"first\",inplace=True,ignore_index=True)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2c79f3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated text in test data:\n",
      "2.12 %\n",
      "time: 16 ms (started: 2022-06-27 07:04:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Looking for duplicates\n",
    "percent_duplicates = round((1-(test['text'].nunique()/len(test['text'])))*100,2)\n",
    "print('Duplicated text in test data:')\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "022f676a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 ms (started: 2022-06-27 07:04:51 +01:00)\n"
     ]
    }
   ],
   "source": [
    "test.drop_duplicates(subset=\"text\",keep=\"first\",inplace=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fccb74c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated text in test data:\n",
      "0.0 %\n",
      "time: 0 ns (started: 2022-06-27 07:04:53 +01:00)\n"
     ]
    }
   ],
   "source": [
    "percent_duplicates = round((1-(test['text'].nunique()/len(test['text'])))*100,2)\n",
    "print('Duplicated text in test data:')\n",
    "print(percent_duplicates,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30e2e914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.92 s (started: 2022-06-27 06:40:44 +01:00)\n"
     ]
    }
   ],
   "source": [
    "train['text'] = train['text'].apply(text_preprocessing)\n",
    "test['text'] = test['text'].apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e1956ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMSON\\AppData\\Local\\Temp/ipykernel_12592/2305434871.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train[\"text\"] = train[\"text\"].str.replace(\".txt\", \" text file\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 281 ms (started: 2022-06-27 06:40:49 +01:00)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMSON\\AppData\\Local\\Temp/ipykernel_12592/2305434871.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test[\"text\"] = test[\"text\"].str.replace(\".txt\", \" text file\")\n"
     ]
    }
   ],
   "source": [
    "# Replace '.txt' with 'text file'\n",
    "train[\"text\"] = train[\"text\"].str.replace(\".txt\", \" text file\")\n",
    "test[\"text\"] = test[\"text\"].str.replace(\".txt\", \" text file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ecb5ce",
   "metadata": {},
   "source": [
    "Great! We have dealt with all the duplicates in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a29b9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 562 ms (started: 2022-06-27 06:40:50 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Removing extra spaces\n",
    "train['text']=train['text'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f001745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2022-06-27 06:40:50 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Removing extra spaces\n",
    "test['text']=test['text'].apply(lambda x: re.sub(' +',' ',x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37edb6a9",
   "metadata": {},
   "source": [
    "###### Create a copy\n",
    "\n",
    "The first step in the preprocessing is to create a copy of the train dataframe for the EDA.In this step we start by determining the length of each text and storing this information in a new column. We then tokenize the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a86cd433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2022-06-27 06:40:50 +01:00)\n"
     ]
    }
   ],
   "source": [
    " df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e33a5ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang_id</th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xho</td>\n",
       "      <td>umgaqo-siseko wenza amalungiselelo kumaziko ax...</td>\n",
       "      <td>220</td>\n",
       "      <td>[umgaqo-siseko, wenza, amalungiselelo, kumazik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xho</td>\n",
       "      <td>i-dha iya kuba nobulumko bokubeka umsebenzi na...</td>\n",
       "      <td>252</td>\n",
       "      <td>[i-dha, iya, kuba, nobulumko, bokubeka, umsebe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>the province of kwazulu-natal department of tr...</td>\n",
       "      <td>264</td>\n",
       "      <td>[the, province, of, kwazulu-natal, department,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nso</td>\n",
       "      <td>o netefatša gore o ba file dilo ka moka tše le...</td>\n",
       "      <td>217</td>\n",
       "      <td>[o, netefatša, gore, o, ba, file, dilo, ka, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ven</td>\n",
       "      <td>khomishini ya ndinganyiso ya mbeu yo ewa maana...</td>\n",
       "      <td>239</td>\n",
       "      <td>[khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lang_id                                               text  length  \\\n",
       "0     xho  umgaqo-siseko wenza amalungiselelo kumaziko ax...     220   \n",
       "1     xho  i-dha iya kuba nobulumko bokubeka umsebenzi na...     252   \n",
       "2     eng  the province of kwazulu-natal department of tr...     264   \n",
       "3     nso  o netefatša gore o ba file dilo ka moka tše le...     217   \n",
       "4     ven  khomishini ya ndinganyiso ya mbeu yo ewa maana...     239   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [umgaqo-siseko, wenza, amalungiselelo, kumazik...  \n",
       "1  [i-dha, iya, kuba, nobulumko, bokubeka, umsebe...  \n",
       "2  [the, province, of, kwazulu-natal, department,...  \n",
       "3  [o, netefatša, gore, o, ba, file, dilo, ka, mo...  \n",
       "4  [khomishini, ya, ndinganyiso, ya, mbeu, yo, ew...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.52 s (started: 2022-06-27 06:40:50 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def lemma(df):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    df['length'] = df['text'].str.len()\n",
    "    df['tokenized'] = df['text'].apply(word_tokenize)\n",
    "    return df\n",
    "\n",
    "df = lemma(df)\n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a2a328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 26s (started: 2022-06-27 06:41:00 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Importing spacy\n",
    "import spacy\n",
    "\n",
    "# Loading model\n",
    "nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n",
    "\n",
    "# Lemmatization with stopwords removal\n",
    "df['lemmatized']=df['text'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0a8a264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>- - - - di a hohela boiqapelo bo hlwahlwa le bongodi bo tsotehang di a hohela di tsamaelana le sehlooho le bongodi bo kgabane di a baleha mosebetsi o kgotsofatsang ho boima ho latela dintlha ka botlalo</th>\n",
       "      <td>- - - - di hohela boiqapelo bo hlwahlwa le bon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>- d - and e - financial years i to be unsafe and ii not containing the exact proportions of ingredients as advertised if so in each case aa which products bb on what basis did the specified product fail the comprehensive inspection and cc what action was taken against the specified manufacturer</th>\n",
       "      <td>- d - e - financial year unsafe ii contain exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>- e-mail bidoffice statssa gov za statistics south africa reserves the right not to consider or to reject all bids or amend modify postpone withdraw or terminates the bidding process at any time for any reason whatsoever office hours - and - mondays to fridays</th>\n",
       "      <td>- e - mail bidoffice statssa gov za statistic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a - tšhupane ya morwalo load index kg ka lebelo la km h a seo se šupago lebelo leo thaere e ka rwalago morwalo wo o itšego ka lona ela hloko gore ditšhupetšo mabapi le morwalo di ka fapana go ya tirišo ya thaere ge eba e dirišwa go goga morwalo goba go sepediša sedirišwa ka tokologo</th>\n",
       "      <td>- tšhupane ya morwalo load index kg ka lebelo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a - vragindeks kg km h a wat beteken die spoed waarteen die band die spesifieke vrag kan dra let daarop dat verskillende vraggraderings van toepassing kan wees indien dit n trekkerband is of slegs n vrylopende implement</th>\n",
       "      <td>- vragindek kg km h wat beteken die spoe waart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                           lemmatized\n",
       "text                                                                                                 \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...  - - - - di hohela boiqapelo bo hlwahlwa le bon...\n",
       "- d - and e - financial years i to be unsafe an...  - d - e - financial year unsafe ii contain exa...\n",
       "- e-mail bidoffice statssa gov za statistics so...  - e - mail bidoffice statssa gov za statistic ...\n",
       "a - tšhupane ya morwalo load index kg ka lebelo...  - tšhupane ya morwalo load index kg ka lebelo ...\n",
       "a - vragindeks kg km h a wat beteken die spoed ...  - vragindek kg km h wat beteken die spoe waart..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 359 ms (started: 2022-06-27 06:44:26 +01:00)\n"
     ]
    }
   ],
   "source": [
    "df_grouped=df[['text','lemmatized']].groupby(by='text').agg(lambda x:' '.join(x))\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e75f3545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMSON\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aabameli</th>\n",
       "      <th>aaent</th>\n",
       "      <th>aak</th>\n",
       "      <th>aan</th>\n",
       "      <th>aanbeveel</th>\n",
       "      <th>aanbevele</th>\n",
       "      <th>aanbeveling</th>\n",
       "      <th>aanbevole</th>\n",
       "      <th>aanbie</th>\n",
       "      <th>...</th>\n",
       "      <th>ṱuwa</th>\n",
       "      <th>ṱuwe</th>\n",
       "      <th>ṱuwedza</th>\n",
       "      <th>ṱuwedzi</th>\n",
       "      <th>ṱuṱuwedza</th>\n",
       "      <th>ṱuṱuwedzaho</th>\n",
       "      <th>ṱuṱuwedze</th>\n",
       "      <th>ṱuṱuwedzea</th>\n",
       "      <th>ṱuṱuwedzwa</th>\n",
       "      <th>ṱuṱuwedzwe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>- - - - di a hohela boiqapelo bo hlwahlwa le bongodi bo tsotehang di a hohela di tsamaelana le sehlooho le bongodi bo kgabane di a baleha mosebetsi o kgotsofatsang ho boima ho latela dintlha ka botlalo</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>- d - and e - financial years i to be unsafe and ii not containing the exact proportions of ingredients as advertised if so in each case aa which products bb on what basis did the specified product fail the comprehensive inspection and cc what action was taken against the specified manufacturer</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>- e-mail bidoffice statssa gov za statistics south africa reserves the right not to consider or to reject all bids or amend modify postpone withdraw or terminates the bidding process at any time for any reason whatsoever office hours - and - mondays to fridays</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 139559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    aa  aabameli  aaent  aak  \\\n",
       "text                                                                           \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...   0         0      0    0   \n",
       "- d - and e - financial years i to be unsafe an...   1         0      0    0   \n",
       "- e-mail bidoffice statssa gov za statistics so...   0         0      0    0   \n",
       "\n",
       "                                                    aan  aanbeveel  aanbevele  \\\n",
       "text                                                                            \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...    0          0          0   \n",
       "- d - and e - financial years i to be unsafe an...    0          0          0   \n",
       "- e-mail bidoffice statssa gov za statistics so...    0          0          0   \n",
       "\n",
       "                                                    aanbeveling  aanbevole  \\\n",
       "text                                                                         \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...            0          0   \n",
       "- d - and e - financial years i to be unsafe an...            0          0   \n",
       "- e-mail bidoffice statssa gov za statistics so...            0          0   \n",
       "\n",
       "                                                    aanbie  ...  ṱuwa  ṱuwe  \\\n",
       "text                                                        ...               \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...       0  ...     0     0   \n",
       "- d - and e - financial years i to be unsafe an...       0  ...     0     0   \n",
       "- e-mail bidoffice statssa gov za statistics so...       0  ...     0     0   \n",
       "\n",
       "                                                    ṱuwedza  ṱuwedzi  \\\n",
       "text                                                                   \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...        0        0   \n",
       "- d - and e - financial years i to be unsafe an...        0        0   \n",
       "- e-mail bidoffice statssa gov za statistics so...        0        0   \n",
       "\n",
       "                                                    ṱuṱuwedza  ṱuṱuwedzaho  \\\n",
       "text                                                                         \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...          0            0   \n",
       "- d - and e - financial years i to be unsafe an...          0            0   \n",
       "- e-mail bidoffice statssa gov za statistics so...          0            0   \n",
       "\n",
       "                                                    ṱuṱuwedze  ṱuṱuwedzea  \\\n",
       "text                                                                        \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...          0           0   \n",
       "- d - and e - financial years i to be unsafe an...          0           0   \n",
       "- e-mail bidoffice statssa gov za statistics so...          0           0   \n",
       "\n",
       "                                                    ṱuṱuwedzwa  ṱuṱuwedzwe  \n",
       "text                                                                        \n",
       "- - - - di a hohela boiqapelo bo hlwahlwa le bo...           0           0  \n",
       "- d - and e - financial years i to be unsafe an...           0           0  \n",
       "- e-mail bidoffice statssa gov za statistics so...           0           0  \n",
       "\n",
       "[3 rows x 139559 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.09 s (started: 2022-06-27 06:44:27 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Creating Document Term Matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv=CountVectorizer(analyzer='word')\n",
    "data=cv.fit_transform(df_grouped['lemmatized'])\n",
    "df_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\n",
    "df_dtm.index=df_grouped.index\n",
    "df_dtm.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88673db",
   "metadata": {},
   "source": [
    "## EXPLORATORY data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "83472e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 0 ns (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def frequency(text):\n",
    "    # Count vectorizer excluding english stopwords\n",
    "    cv = CountVectorizer(stop_words='english')\n",
    "    words = cv.fit_transform(text)\n",
    "    \n",
    "    # Count the words in the texts and determine the frequency of each word\n",
    "    sum_words = words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, i]) for word, i in cv.vocabulary_.items()]\n",
    "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Create a dataframe to store the top 25 words and their frequencies\n",
    "    frequency = pd.DataFrame(words_freq, columns=['word', 'freq'])\n",
    "    frequency = frequency.head(25)\n",
    "    \n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce76d209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lang_id</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>length</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tokenized</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lemmatized</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  freq\n",
       "0     lang_id     1\n",
       "1        text     1\n",
       "2      length     1\n",
       "3   tokenized     1\n",
       "4  lemmatized     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "frequency(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef4c0a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 93 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Importing wordcloud for plotting word clouds and textwrap for wrapping longer text\n",
    "#from wordcloud import WordCloud\n",
    "#from textwrap import wrap\n",
    "\n",
    "# Function for generating word clouds\n",
    "#def generate_wordcloud(data,title):\n",
    "# plt.figure(figsize=(10,8))\n",
    "#  plt.imshow(wc, interpolation='bilinear')\n",
    " # plt.axis(\"off\")\n",
    " # plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n",
    "  #plt.show()\n",
    "  # Transposing document term matrix\n",
    "#df_dtm=df_dtm.transpose()\n",
    "\n",
    "# Plotting word cloud for each product\n",
    "#for index,product in enumerate(df_dtm.columns):\n",
    "#generate_wordcloud(df_dtm[product].sort_values(ascending=False),product)\n",
    "# please uncomment it was wasting time and I need to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b352bb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "#vocab = set()\n",
    "#corpus= [x.split() for x in df['text'].tolist()]\n",
    "#for sentence in corpus:\n",
    "  #for word in sentence:\n",
    " #   vocab.add(word.lower())\n",
    "#print(\"Number of distinct words in raw data: \", len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563f43a5",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1c800",
   "metadata": {},
   "source": [
    "### Splitting out X (indepedent) and Y (target/dependent) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07b2fc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 94 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "X = train['text']\n",
    "y = train['lang_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7de9d07",
   "metadata": {},
   "source": [
    "### Splitting of Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b1230816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9873d03",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a3bb400",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "classifiers = [LinearSVC(random_state=42),\n",
    "                SVC(),\n",
    "                #DecisionTreeClassifier(),\n",
    "                #RandomForestClassifier(n_estimators=100, max_depth=2,\n",
    "                                     #random_state=0, class_weight=\"balanced\"),\n",
    "                #MLPClassifier(alpha=1e-5,\n",
    "                             #hidden_layer_sizes=(5, 2),\n",
    "                             #random_state=42),\n",
    "               LogisticRegression(random_state=42,\n",
    "                                  multi_class='ovr',\n",
    "                                  n_jobs=1,\n",
    "                                  C=1e5,\n",
    "                                  max_iter=100000),\n",
    "               KNeighborsClassifier(n_neighbors=5),\n",
    "               MultinomialNB(),\n",
    "               ComplementNB(),\n",
    "               SGDClassifier(loss='hinge',\n",
    "                             penalty='l2',\n",
    "                             alpha=1e-3,\n",
    "                             random_state=42,\n",
    "                             max_iter=5,\n",
    "                             tol=None)\n",
    "                #GradientBoostingClassifier(),\n",
    "                #xgb.XGBClassifier(learning_rate=0.1,\n",
    "                #                 n_estimators=1000,\n",
    "                #                 max_depth=5,\n",
    "                #                min_child_weight=1,\n",
    "                #                 gamma=0,\n",
    "                #                subsample=0.8,\n",
    "                #                 colsample_bytree=0.8,\n",
    "                #                 nthread=4,\n",
    "                #                 seed=27)\n",
    "               ]\n",
    "# The commented code took tool long to load hence the reason for excluding them also, they didn't really perform as much as the ran"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a62d06",
   "metadata": {},
   "source": [
    "### Creating Function for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "faab455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms (started: 2022-06-27 06:44:30 +01:00)\n"
     ]
    }
   ],
   "source": [
    "def models_building(classifiers, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    This function takes in a list of classifiers\n",
    "    and both the train and validation sets\n",
    "    and return a summary of F1-score and\n",
    "    processing time as a dataframe\n",
    "\n",
    "    Input:\n",
    "    classifiers: a list of classifiers to train\n",
    "                 datatype: list\n",
    "    X_train: independent variable for training\n",
    "             datatype: series\n",
    "    y_train: dependent variable for training\n",
    "             datatype: series\n",
    "    X_val: independent variable for validation\n",
    "           datatype: series\n",
    "    y_val: dependent variable for validation\n",
    "           datatype: series\n",
    "\n",
    "    Output:\n",
    "    model_summary: F1 Score for all the classifiers\n",
    "                   datatype: dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    models_summary = {}\n",
    "\n",
    "    # Pipeline to balance the classses and then to build the model\n",
    "    for clf in classifiers:\n",
    "        clf_text = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                       max_df=0.9,\n",
    "                                                       ngram_range=(1, 2))),\n",
    "                             ('clf', clf)])\n",
    "\n",
    "        # Logging the Execution Time for each model\n",
    "        start_time = time.time()\n",
    "        clf_text.fit(X_train, y_train)\n",
    "        predictions = clf_text.predict(X_val)\n",
    "        run_time = time.time()-start_time\n",
    "\n",
    "        # Output for each model\n",
    "        models_summary[clf.__class__.__name__] = {\n",
    "            'F1-Macro': metrics.f1_score(y_val,\n",
    "                                         predictions,\n",
    "                                         average='macro'),\n",
    "            'F1-Accuracy': metrics.f1_score(y_val, predictions,\n",
    "                                            average='micro'),\n",
    "            'F1-Weighted': metrics.f1_score(y_val,\n",
    "                                            predictions,\n",
    "                                            average='weighted'),\n",
    "            'Execution Time': run_time}\n",
    "\n",
    "    return pd.DataFrame.from_dict(models_summary, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca41d64",
   "metadata": {},
   "source": [
    "### Execution of the Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30895822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-Macro</th>\n",
       "      <th>F1-Accuracy</th>\n",
       "      <th>F1-Weighted</th>\n",
       "      <th>Execution Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.996586</td>\n",
       "      <td>0.996494</td>\n",
       "      <td>0.996491</td>\n",
       "      <td>7.030391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.996055</td>\n",
       "      <td>0.995993</td>\n",
       "      <td>0.995993</td>\n",
       "      <td>6.791515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearSVC</th>\n",
       "      <td>0.994879</td>\n",
       "      <td>0.994825</td>\n",
       "      <td>0.994826</td>\n",
       "      <td>8.972674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.994879</td>\n",
       "      <td>0.994825</td>\n",
       "      <td>0.994826</td>\n",
       "      <td>160.258196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.992723</td>\n",
       "      <td>0.992654</td>\n",
       "      <td>0.992671</td>\n",
       "      <td>471.099693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.982782</td>\n",
       "      <td>0.982805</td>\n",
       "      <td>0.982716</td>\n",
       "      <td>7.092083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.969662</td>\n",
       "      <td>0.969449</td>\n",
       "      <td>0.969222</td>\n",
       "      <td>12.683124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      F1-Macro  F1-Accuracy  F1-Weighted  Execution Time\n",
       "ComplementNB          0.996586     0.996494     0.996491        7.030391\n",
       "MultinomialNB         0.996055     0.995993     0.995993        6.791515\n",
       "LinearSVC             0.994879     0.994825     0.994826        8.972674\n",
       "LogisticRegression    0.994879     0.994825     0.994826      160.258196\n",
       "SVC                   0.992723     0.992654     0.992671      471.099693\n",
       "SGDClassifier         0.982782     0.982805     0.982716        7.092083\n",
       "KNeighborsClassifier  0.969662     0.969449     0.969222       12.683124"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11min 15s (started: 2022-06-27 06:44:31 +01:00)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "classifiers_df = models_building(classifiers, X_train, y_train, X_val, y_val)\n",
    "ordered_df = classifiers_df.sort_values('F1-Macro', ascending=False)\n",
    "ordered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c463e9",
   "metadata": {},
   "source": [
    "### Comparing Classification Methods\n",
    "The most performing models were the  Complement Naive Bayes and the Multinomial Naive Bayes with F1-Macro of 99.8% and accuracy of 99.7% while closely followed by Linear Support Vector Classifier,Logistic Regression, Support Vector Machine etc.\n",
    "\n",
    "Hyperameter tuning is carried out to improve the F1-Macro score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd2854e",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning on Most Performing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5874df48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16 ms (started: 2022-06-27 06:55:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "# Refining the train-test split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a61324ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms (started: 2022-06-27 06:55:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1fab0a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00        21\n",
      "         eng       1.00      1.00      1.00        36\n",
      "         nbl       1.00      1.00      1.00        29\n",
      "         nso       1.00      1.00      1.00        33\n",
      "         sot       1.00      1.00      1.00        32\n",
      "         ssw       1.00      1.00      1.00        20\n",
      "         tsn       1.00      1.00      1.00        31\n",
      "         tso       1.00      1.00      1.00        27\n",
      "         ven       1.00      1.00      1.00        18\n",
      "         xho       1.00      1.00      1.00        18\n",
      "         zul       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "time: 19 s (started: 2022-06-27 06:55:46 +01:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Creating a pipeline for the gridsearch\n",
    "param_grid = {'alpha': [0.1, 1, 5, 10]}  # setting parameter grid\n",
    "\n",
    "tuned_mnb = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                max_df=0.8,\n",
    "                                                ngram_range=(1, 2))),\n",
    "                      ('mnb', GridSearchCV(MultinomialNB(),\n",
    "                                           param_grid=param_grid,\n",
    "                                           cv=5,\n",
    "                                           n_jobs=-1,\n",
    "                                           scoring='f1_weighted'))\n",
    "                      ])\n",
    "\n",
    "tuned_mnb.fit(X_train, y_train)  # Fitting the model\n",
    "\n",
    "y_pred_mnb = tuned_mnb.predict(X_val)  # predicting the fit on validation set\n",
    "\n",
    "print(classification_report(y_val, y_pred_mnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ba768d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         afr       1.00      1.00      1.00        21\n",
      "         eng       1.00      1.00      1.00        36\n",
      "         nbl       1.00      1.00      1.00        29\n",
      "         nso       1.00      1.00      1.00        33\n",
      "         sot       1.00      1.00      1.00        32\n",
      "         ssw       1.00      1.00      1.00        20\n",
      "         tsn       1.00      1.00      1.00        31\n",
      "         tso       1.00      1.00      1.00        27\n",
      "         ven       1.00      1.00      1.00        18\n",
      "         xho       1.00      1.00      1.00        18\n",
      "         zul       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           1.00       300\n",
      "   macro avg       1.00      1.00      1.00       300\n",
      "weighted avg       1.00      1.00      1.00       300\n",
      "\n",
      "time: 14.9 s (started: 2022-06-27 06:56:05 +01:00)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Creating a pipeline for the gridsearch\n",
    "param_grid = {'alpha': [0.1, 1, 5, 10]}  # setting parameter grid\n",
    "\n",
    "tuned_cnb = Pipeline([('tfidf', TfidfVectorizer(min_df=1,\n",
    "                                                max_df=0.8,\n",
    "                                                ngram_range=(1, 2))),\n",
    "                      ('cnb', GridSearchCV(ComplementNB(),\n",
    "                                           param_grid=param_grid,\n",
    "                                           cv=5,\n",
    "                                           n_jobs=-1,\n",
    "                                           scoring='f1_weighted'))\n",
    "                      ])\n",
    "\n",
    "tuned_cnb.fit(X_train, y_train)  # Fitting the model\n",
    "\n",
    "y_pred_cnb = tuned_cnb.predict(X_val)  # predicting the fit on validation set\n",
    "\n",
    "print(classification_report(y_val, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ab2b8",
   "metadata": {},
   "source": [
    "### Creating File for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a3b5f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 562 ms (started: 2022-06-27 06:56:20 +01:00)\n"
     ]
    }
   ],
   "source": [
    "submission_trial = pd.DataFrame(test['index'])\n",
    "submission_trial['lang_id'] = tuned_mnb.predict(test['text'])\n",
    "submission_trial.to_csv('submission_mn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb4459",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Several algorithms were tried and Complement Naive Bayes and Multinomial Naive Bayes classifier was the most performing. They performed very well on the training and validation datasets with an accuracy score of over 99% and F1 Macro score of over 99%. After testing the fitted model on the held-out/unseen dataset, they were able to predict the classes of languages with an F1 Score of about 99%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bfda49",
   "metadata": {},
   "source": [
    "### References\n",
    "https://colab.research.google.com/drive/1eQydhzxK03z4_20_A9dunOq04trRYuZG?usp=sharing#scrollTo=InfhMWcIHlR_\n",
    "https://www.analyticsvidhya.com/blog/2020/04/beginners-guide-exploratory-data-analysis-text-data/\n",
    "https://stackoverflow.com/questions/46864696/how-to-resolve-python-error-while-generating-pie-chart-valueerror-explode-m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9850c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
